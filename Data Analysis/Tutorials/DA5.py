import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

unemp_county = pd.read_csv("Datasets/output.csv")
unemp_county.head()

#We now want to create another dataframe for our minimum wage in order to merge the results

df = pd.read_csv("Datasets/minwage.csv")

act_min_wage = pd.DataFrame()

for name, group in df.groupby("State"):
	if act_min_wage.empty:
		act_min_wage = group.set_index("Year")[["Low.2018"]].rename(columns={"Low.2018":name})
	else:
		act_min_wage = act_min_wage.join(group.set_index("Year")[["Low.2018"]].rename(columns={"Low.2018":name}))

#We now want to fix the missing data, remove the NaN
act_min_wage = act_min_wage.replace(0, np.NaN).dropna(axis=1)

#We want to take the minimum wage and add that to a column in our unemployment set
#We will do that by creating a new column and then mapping the values
#There is most likely a better way to do so but it will give us a way of reliably creating new column values in pandas
#It is not the most efficient and can be slow


def get_min_wage(year, state): #state means county
	try:
		return act_min_wage.loc[year][state] #loc stands for locate
	except:
		return np.NaN

#We now test our string
print(get_min_wage(2012, "Colorado"))

#Our aim is to now map this function to a column in the dataframe 
unemp_county["min_wage"] = list(map(get_min_wage, unemp_county["Year"], unemp_county["State"])) # Since the map doesn't work on its own we need to convert the data item to a list
#We had to convert it to a list at the very end because with pandas a new column can be generated by a list of things
#This method will be relatively slow

#Check to see
unemp_county[["Rate", "min_wage"]].corr()
unemp_county[["Rate", "min_wage"]].cov()

pres16 = pd.read_csv("Datasets/pres16results.csv")

#We will now get the latest unemployment data to make what we work with much smaller
#We can now filter the dataframe to jut February 2015

county_2015 = unemp_county.copy()[(unemp_county["Year"] == 2015) &  (unemp_county["Month"] == "February")]

pres16["st"].unique() #will give us a list of our states as postal code

#Since we have a dictionary with postal codes and the abbreviations we can just map them
state_abbv = pd.read_csv("datasets/state_abbv.csv")
state_abbv = state_abbv[["Postal Code"]]


state_abbv_dict = state_abbv.to_dict()["Postal Code"]
county_2015["State"] = county_2015["State"].map(State_abbv_dict)

#We want to merge pres16 and county_2015 together
#We want to merge them together based on the year and the state
#The state and county are named differently on the 2 datasets so we want to rename them
pres16.rename(columns={"county":"County", "st":"State"}, inplace=True) #The first becomes the second

#Setting county and state as a double index
for df in county [county_2015, pres16]:
	df.set_index(["County", "State"], inplace=True)

#We want only the links to Donald Trump
pres16 = pres16[pres16['cand'] == "Donald Trump"]
pres16 = pres16[["pct"]]
pres16.dropna(inplace=True)

#To merge them we will make a whole new dataframe 
all_together = county_2015.merge(pre16, on=["County", "State"])
all_together.dropna(inplace=True)

all_together.drop("Year", axis=1, inplace=True)

print(all_together.corr())
print(all_together.cov())


